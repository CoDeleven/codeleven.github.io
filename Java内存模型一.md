---
title: Java内存模型
date: 2018-04-29 11:13:43
tags: JVM
---

相信许多在**多线程**前线作战的伙伴们经常会遇到一种叫做**内存可见性**的大麻烦。这个麻烦可以简单粗暴的用*synchronized*解决，也可以很巧妙的用一些轻量级的同步原语解决。虽然能解决问题的都是好方案，但是在程序人生的旅途上，后者才是更为远见的选择。

在面对**内存可见性**这个问题时，我们不得不先去学习一个叫做**内存模型**的东西。这个模型解释了**如何解决多线程间的通讯** 和 **如何实现多线程间的同步** 两个问题。
传统上有两种模型，一种叫做**内存共享模型**，另外一种则时**消息传递模型**。而Java采用了一种叫做**内存共享**的内存模型，后文简称**JMM**。这个抽象概念主要描述了：
    
    线程间的共享变量存储在主内存中，每个线程拥有自己的本地内存，每个本地内存上都有该线程读/写变量的副本。

![JMM概念图](https://blog-1252749790.file.myqcloud.com/JavaConcurrent/JMMConcept.png)

然而了解这个模型还不够，我们还要知道在Java编译、运行阶段都会有一种优化手段——**重排序**。重排序分为以下三种类型：

- 编译器优化的重排序。在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序
- 指令集并行的重排序。现代处理器采用了指令级并行技术（Instruction-Level Parallelism）来将多条指令重叠执行，如果不存在数据以来，处理器可以改变语句对应机器指令的执行顺序。
- 内存系统的重排序。由于处理器适用缓存和读/写缓冲区，这使得加载和存储操作看上去是乱序执行的。

第1类属于**编译器重排序**，第2、3类型属于**处理器重排序**。而JMM作为语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，禁止特定类型的编译器重排序和处理器重排序，尽可能地满足处理器级别的重排序优化，又让程序员自己把握优化程度。正如我们前面所讲的，遇到**内存可见性问题**，可以简单的用*synchronized* 大范围的禁止重排序，也可以根据实际情况，选用*volatile、final等轻量级同步原语* 仅仅禁止关键部分的重排序。

总而言之，发生**内存可见性问题**的原因不外乎两点：

1. 本地内存（在CPU那个层面理解为缓冲区）在作怪
2. 重排序

第一点属于硬件架构问题，基本上是无法从语言层面进行解决。故通过**解决重排序问题**来提出解决**内存可见性问题**的方案。

## 深入底层，了解本地内存
现代处理器都会配备一个写缓冲区，该缓冲区用来暂存写入的变量，保证指令流水线持续运行，避免CPU停下来等待向内存写入数据而产生的延迟；同时也能合并对同一地址的多次写。虽然写缓冲区好处多多，但是只对自己的CPU可见。这个特性在**重排序**的加持下，容易发生CPU对内存的读/写顺序 和实际内存发生的读/写顺序 不一致的情况。

假设现在有这样一个情况，线程A和线程B并发执行：

* 处理器A：
     * int a = 1;
     * int a = b;
* 处理器B：
     * int b = 2;
     * int b = a;

这样的程序偶尔会出现预料之外的结果，比如a和b均为0，或者a=1，b=1等等。具体原因如下图所示

![](https://blog-1252749790.file.myqcloud.com/JavaConcurrent/CPUCacheFlow2.png)

这里CPU0 和 CPU1 均往自己的缓冲区写入数据，然后从内存中读取共享变量，最后才把写缓冲区中的数据刷新至主内存。当以这种时许执行时，就会出现a = y = 0的情况。

从内存实际执行角度看，下面的图例可能更符合直观感受：先写入缓冲区，缓冲区刷新到主内存，最后CPU从主内存中读取。对处理器来说，它认为执行顺序是①、②、③，但是实际操作情况却是①、③、②。此时CPU0的内存操作顺序被重排序了。

![](https://blog-1252749790.file.myqcloud.com/JavaConcurrent/CPUCacheFlow.png)


为了解决上述的问题，处理器提供了一种被称作**内存屏障（Memory Fence）** 的CPU指令，该指令可以处理重排序和可见性问题。Java编译器在生成指令序列时，会在适当位置中插入内存屏障来禁止特定类型的处理器重排序（所以那些同步原语本质都是**内存屏障**在其作用）。JVM把内存屏障分为4类，如下所示：

屏障类型 | 指令示例 | 说明 |
- | :-: | :-: |
LoadLoad | Load1;LoadLoad;Load2 | 在Load2及所有后续读取指令之前，Load1读取数据完毕 |
StoreStore | Store1;StoreStore;Store2 | 在Store2及所有后续写入指令执行前，Store1写入的数据对其他处理器可见 |
LoadStore | Load1;LoadStore;Store2 | 在Store2及所有后续写入指令刷新到主内存前，Load1读取数据完毕|
StoreLoad | Store1;StoreLoad;Load2 | 在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见 |

最后一个StoreLoad指令是万能指令（有些处理器不支持前三种指令），兼具前三种指令的功能，且开销最大。
内存屏障在禁止重排序，保证内存可见性方面作用极大，为后续JMM的规则（保证）打下了基础。

## 解决内存可见性问题
为了能让JVM在一定程度上(因为重排序就是优化)保持**重排序**，又能解决**内存可见性问题**。Java 在 JSR-133 里推出了Happens-Before规则，修改了**volatile、final等同步原语**。

### 程序顺序规则(as-if-serial)
上面我们都了解到了**处理器重排序** 对 CPU的影响，现在我们看看**编译器重排序**对单线程的影响
```java
int a = 1; // ①
int b = 3; // ②
int c = a * b; // ③
```
在单线程的环境下运行这段代码，会和直观感受一样，它的结果是3，但是它的执行顺序是否和想象中一样就不得而知了。这就引出了一个这么概念——if as serial，这个概念主要描述了 **不管如何重排序，单线程程序的执行结果不能被改变**，编译器、runtime和处理器都必须遵守这个as-if-serial语义(处理器本身是不会遵守的，但是有JMM的控制)。

因为③依赖①、②的数据，所以为了保证结果一致，无论如何③都不会被排到①或②之前。

as-if-serial语义使单线程程序员无需担心重排序会干扰他们，也无需担心内存可见性问题。这是JMM对程序员作的第一个保证：在单线程下，你不用管重排不重排，结果肯定给你保证一样。

但是面对多线程的情况下，这个语义显得有点单薄，无法保证 多线程的重排序不会对程序有影响。为了能让多线程也无需担心重排序和内存可见性问题，Java提供了一些同步原语，以达到理想中的**顺序一致性模型**。


### 顺序一致性模型
